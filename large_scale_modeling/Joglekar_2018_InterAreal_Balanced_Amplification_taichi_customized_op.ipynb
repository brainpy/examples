{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *(Joglekar, et. al, 2018)*: Inter-areal Balanced Amplification taichi customized operators\n",
    "\n",
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/brainpy/examples/blob/main/large_scale_modeling/Joglekar_2018_InterAreal_Balanced_Amplification_taichi_customized_op.ipynb)\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/brainpy/examples/blob/main/large_scale_modeling/Joglekar_2018_InterAreal_Balanced_Amplification_taichi_customized_op.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using taichi customized operators to implement the model in *(Joglekar, et. al, 2018)*.:\n",
    "\n",
    "- Joglekar, Madhura R., et al. \"Inter-areal balanced amplification enhances signal propagation in a large-scale circuit model of the primate cortex.\" Neuron 98.1 (2018): 222-234."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brainpy as bp\n",
    "import brainpy.math as bm\n",
    "from brainpy import neurons\n",
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from typing import Tuple, Optional\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should import taichi before customize your operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import taichi as ti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there are some random number generators which were defined in BrainPy, We need to use these in taichi kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brainpy.math.tifunc import (lfsr88_key, lfsr88_random_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select the target platform you want to run your customized operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm.set_platform('cpu')\n",
    "bm.set_platform('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the kernel with taichi.kernel decorater\n",
    "\n",
    "For customized your operators, you can find the tutorial at [CPU and GPU Operator Customization with Taichi](https://brainpy.tech/docs/tutorial_advanced/operator_custom_with_taichi.html)\n",
    "\n",
    "Below is defining a Taichi kernel for processing multiple areas with event-driven updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel receive spikes from **the excitory neurons** of one region and calculate the output currents to the neurons of all regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def _multiple_area_event_mv_prob_homo_irregular_cpu_E(\n",
    "        events: ti.types.ndarray(ndim=1),  # 1D array of events, where nonzero values indicate a spike.\n",
    "        weight: ti.types.ndarray(ndim=1),  # 1D array of weights, one per area, to be added to the output on an event.\n",
    "        clen: ti.types.ndarray(ndim=1),    # 1D array containing the upper limit for random integer generation.\n",
    "        seed: ti.types.ndarray(ndim=1),    # 1D array of seeds, one per area, for random number generation.\n",
    "        out: ti.types.ndarray(ndim=2)      # 2D output array where current updates are made based on events and weights.\n",
    "):\n",
    "    num_row = out.shape[1]  # Number of rows in the output array.\n",
    "    num_col = events.shape[0]  # Number of columns (events) to process.\n",
    "    clen0 = clen[0]  # Upper limit for random integer generation.\n",
    "\n",
    "    for i_col in range(num_col):  # Iterate over each event.\n",
    "        if events[i_col] != 0.:  # Check if the current event occurred (nonzero).\n",
    "            for i_area in range(out.shape[0]):  # Iterate over each area.\n",
    "                key = lfsr88_key(seed[i_area] + i_col)  # Generate an initial key for random numbers.\n",
    "                key, i_row = lfsr88_random_integers(key, 0, clen0 - 1)  # Generate the first random row index.\n",
    "                while i_row < num_row:  # Ensure the random index is within bounds.\n",
    "                    out[i_area, i_row] += weight[i_area]  # Update the output array with the weight.\n",
    "                    key, inc = lfsr88_random_integers(key, 1, clen0)  # Generate the next random increment.\n",
    "                    i_row += inc  # Update the row index based on the random increment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GPU version, almost as same above kernel. The only difference is that we use `ti.ndrange` to merge two for loops into one for loop in order to improve the parallelism on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def _multiple_area_event_mv_prob_homo_irregular_gpu_E(\n",
    "        events: ti.types.ndarray(ndim=1),\n",
    "        weight: ti.types.ndarray(ndim=1),\n",
    "        clen: ti.types.ndarray(ndim=1),\n",
    "        seed: ti.types.ndarray(ndim=1),\n",
    "        out: ti.types.ndarray(ndim=2)\n",
    "):\n",
    "    num_row = out.shape[1]\n",
    "    num_col = events.shape[0]\n",
    "    clen0 = clen[0]\n",
    "    area_num = out.shape[0]\n",
    "    \n",
    "    # Due to the arch of GPU, use ti.ndrange for parallel processing across events and areas.\n",
    "    for i_col, i_area in ti.ndrange(num_col, area_num):\n",
    "        if events[i_col] != 0.:\n",
    "            key = lfsr88_key(seed[i_area] + i_col)\n",
    "            key, i_row = lfsr88_random_integers(key, 0, clen0 - 1)\n",
    "            while i_row < num_row:\n",
    "                out[i_area, i_row] += weight[i_area]\n",
    "                key, inc = lfsr88_random_integers(key, 1, clen0)\n",
    "                i_row += inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel receive spikes from **the inhibitory neurons** of all region and calculate the output currents to the neurons of all regions. (Inhibitory neurons here only affect neurons in their own brain region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def _multiple_area_event_mv_prob_homo_irregular_cpu_I(\n",
    "        events: ti.types.ndarray(ndim=2), # 2D array of events, where nonzero values indicate a spike in a region .\n",
    "        weight: ti.types.ndarray(ndim=1), # 1D array of weights, one per area, to be added to the output on an event.\n",
    "        clen: ti.types.ndarray(ndim=1),   # 1D array containing the upper limit for random integer generation.\n",
    "        seed: ti.types.ndarray(ndim=1),   # 1D array of seeds, one per area, for random number generation.\n",
    "        out: ti.types.ndarray(ndim=2)     # 2D output array where current updates are made based on events and weights.\n",
    "):\n",
    "    num_row = out.shape[1] # Number of rows in the output array.\n",
    "    num_col = events.shape[1] # Number of columns (events) to process.\n",
    "    clen0 = clen[0] # Upper limit for random integer generation.\n",
    "    weight0 = weight[0] # Each area has same weight\n",
    "\n",
    "    for i_col in range(num_col): # Iterate over each event.\n",
    "        for i_area in range(out.shape[0]): # Inhibitory neurons affect only those in their own region\n",
    "            if events[i_area, i_col] != 0.: # Check if the current event occurred (nonzero).\n",
    "                key = lfsr88_key(seed[i_area] + i_col) # Generate an initial key for random numbers.\n",
    "                key, i_row = lfsr88_random_integers(key, 0, clen0 - 1) # Generate the first random row index.\n",
    "                while i_row < num_row: # Ensure the random index is within bounds.\n",
    "                    out[i_area, i_row] += weight0 # Update the output array with the weight.\n",
    "                    key, inc = lfsr88_random_integers(key, 1, clen0) # Generate the next random increment.\n",
    "                    i_row += inc # Update the row index based on the random increment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GPU version, almost as same above kernel. The only difference is that we use `ti.ndrange` to merge two for loops into one for loop in order to improve the parallelism on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def _multiple_area_event_mv_prob_homo_irregular_gpu_I(\n",
    "        events: ti.types.ndarray(ndim=1),\n",
    "        weight: ti.types.ndarray(ndim=1),\n",
    "        clen: ti.types.ndarray(ndim=1),\n",
    "        seed: ti.types.ndarray(ndim=1),\n",
    "        out: ti.types.ndarray(ndim=2)\n",
    "):\n",
    "    num_row = out.shape[1]\n",
    "    num_col = events.shape[1]\n",
    "    weight0 = weight[0]\n",
    "    clen0 = clen[0]\n",
    "    area_num = out.shape[0]\n",
    "\n",
    "    # Due to the arch of GPU, use ti.ndrange for parallel processing across events and areas.\n",
    "    for i_col, i_area in ti.ndrange(num_col, area_num):\n",
    "        if events[i_area, i_col] != 0.:\n",
    "            key = lfsr88_key(seed[i_area] + i_col)\n",
    "            key, i_row = lfsr88_random_integers(key, 0, clen0 - 1)\n",
    "            while i_row < num_row:\n",
    "                out[i_area, i_row] += weight0\n",
    "                key, inc = lfsr88_random_integers(key, 1, clen0)\n",
    "                i_row += inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the kernel to BrainPy by `bm.XLACustomOp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_multiple_area_event_mv_prob_homo_irregular_p_E = bm.XLACustomOp(cpu_kernel=_multiple_area_event_mv_prob_homo_irregular_cpu_E, \n",
    "                                                                 gpu_kernel=_multiple_area_event_mv_prob_homo_irregular_gpu_E)\n",
    "_multiple_area_event_mv_prob_homo_irregular_p_I = bm.XLACustomOp(cpu_kernel=_multiple_area_event_mv_prob_homo_irregular_cpu_I, \n",
    "                                                                 gpu_kernel=_multiple_area_event_mv_prob_homo_irregular_gpu_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callable apis for further encapsulation\n",
    "This API receive spikes from **the excitory neurons** of one region and calculate the output currents to the neurons of all regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_area_customized_op_E(\n",
    "        events: jax.Array,  # Input events, expected to be a 1D array.\n",
    "        weight: float,  # Uniform weight for all updates.\n",
    "        seed: list[int],  # List of seeds for random number generation of each region\n",
    "        conn_prob: float,  # Connection probability between events and areas.\n",
    "        *,\n",
    "        shape: Tuple[int, int],  # Shape of the output matrix.\n",
    "        area_num: int,  # Number of areas (rows in the output matrix).\n",
    "):\n",
    "    # Convert inputs to JAX arrays for compatibility.\n",
    "    events = bm.as_jax(events)\n",
    "    if isinstance(weight, float): weight = bm.as_jax(weight)\n",
    "    weight = jnp.atleast_1d(bm.as_jax(weight))\n",
    "\n",
    "    # Calculate the connection length based on connection probability.\n",
    "    conn_len = jnp.ceil(1 / conn_prob) * 2 - 1\n",
    "    conn_len = jnp.asarray(jnp.atleast_1d(conn_len), dtype=jnp.int32)\n",
    "\n",
    "    # Define the shape of the output matrix and verify shape compatibility.\n",
    "    out_shape = (area_num, shape[1])\n",
    "    if events.shape[0] != shape[0]:\n",
    "        raise ValueError(f'Shape mismatch, vec {events.shape} @ mat {shape}.')\n",
    "    shape = shape[::-1]\n",
    "\n",
    "    # Call the primitive operation\n",
    "    return _multiple_area_event_mv_prob_homo_irregular_p_E(events,\n",
    "                                                           weight,\n",
    "                                                           conn_len,\n",
    "                                                           seed,\n",
    "                                                           outs=[jax.ShapeDtypeStruct(shape=out_shape, dtype=weight.dtype)],\n",
    "                                                           shape=shape,\n",
    "                                                           area_num=area_num)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This API receive spikes from **the inhibitory neurons** of all region and calculate the output currents to the neurons of all regions. (Inhibitory neurons here only affect neurons in their own brain region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_area_customized_op_I(\n",
    "        events: jax.Array,  # Input events, expected to be a 2D array.\n",
    "        weight: float,  # Uniform weight for all updates.\n",
    "        seed: list[int], # List of seeds for random number generation of each region\n",
    "        conn_prob: float,  # Connection probability.\n",
    "        *,\n",
    "        shape: Tuple[int, int],  # Shape of the output matrix.\n",
    "        area_num: int,  # Number of areas.\n",
    "):\n",
    "    # Similar preparation and validation steps as in multiple_area_customized_op_E.\n",
    "    events = bm.as_jax(events)\n",
    "    if isinstance(weight, float): weight = bm.as_jax(weight)\n",
    "    weight = jnp.atleast_1d(bm.as_jax(weight))\n",
    "    conn_len = jnp.ceil(1 / conn_prob) * 2 - 1\n",
    "    conn_len = jnp.asarray(jnp.atleast_1d(conn_len), dtype=jnp.int32)\n",
    "\n",
    "    # Adjusts shape and calls the primitive operation with validated inputs.\n",
    "    out_shape = (area_num, shape[1])\n",
    "    if events.shape[1] != shape[0]:\n",
    "        raise ValueError(f'Shape mismatch, vec {events.shape} @ mat {shape}.')\n",
    "    shape = shape[::-1]\n",
    "\n",
    "    # Call the primitive operation\n",
    "    return _multiple_area_event_mv_prob_homo_irregular_p_I(events,\n",
    "                                                           weight,\n",
    "                                                           conn_len,\n",
    "                                                           seed,\n",
    "                                                           outs=[jax.ShapeDtypeStruct(shape=out_shape, dtype=weight.dtype)],\n",
    "                                                           shape=shape,\n",
    "                                                           area_num=area_num)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multiple Area Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAreaNet(bp.Network):\n",
    "  def __init__(\n",
    "      self, hier, conn, delay_mat, muIE=0.0475, muEE=.0375, wII=.075,\n",
    "      wEE=.01, wIE=.075, wEI=.0375, extE=15.4, extI=14.0, alpha=4., seed=None,\n",
    "  ):\n",
    "    super(MultiAreaNet, self).__init__()\n",
    "\n",
    "    # data\n",
    "    self.hier = hier\n",
    "    self.conn = conn\n",
    "    self.delay_mat = delay_mat\n",
    "\n",
    "    # parameters\n",
    "    self.muIE = muIE\n",
    "    self.muEE = muEE\n",
    "    self.wII = wII\n",
    "    self.wEE = wEE\n",
    "    self.wIE = wIE\n",
    "    self.wEI = wEI\n",
    "    self.extE = extE\n",
    "    self.extI = extI\n",
    "    self.alpha = alpha\n",
    "    num_area = hier.size\n",
    "    self.num_area = num_area\n",
    "\n",
    "    # neuron models\n",
    "    self.E = neurons.LIF((num_area, 1600),\n",
    "                         V_th=-50., V_reset=-60.,\n",
    "                         V_rest=-70., tau=20., tau_ref=2.,\n",
    "                         noise=3. / bm.sqrt(20.),\n",
    "                         V_initializer=bp.init.Uniform(-70., -50.),\n",
    "                         method='exp_auto',\n",
    "                         keep_size=True,\n",
    "                         ref_var=True)\n",
    "    self.I = neurons.LIF((num_area, 400), V_th=-50., V_reset=-60.,\n",
    "                         V_rest=-70., tau=10., tau_ref=2., noise=3. / bm.sqrt(10.),\n",
    "                         V_initializer=bp.init.Uniform(-70., -50.),\n",
    "                         method='exp_auto',\n",
    "                         keep_size=True,\n",
    "                         ref_var=True)\n",
    "\n",
    "    # delays\n",
    "    self.intra_delay_step = int(2. / bm.get_dt())\n",
    "    self.E_delay_steps = bm.asarray(delay_mat.T / bm.get_dt(), dtype=int)\n",
    "    bm.fill_diagonal(self.E_delay_steps, self.intra_delay_step)\n",
    "    self.Edelay = bm.LengthDelay(self.E.spike, delay_len=int(self.E_delay_steps.max()))\n",
    "    self.Idelay = bm.LengthDelay(self.I.spike, delay_len=self.intra_delay_step)\n",
    "\n",
    "    # synapse model\n",
    "    self.f_EE_current = partial(multiple_area_customized_op_E, conn_prob=0.1, shape=(1600, 1600), area_num=num_area)\n",
    "    self.f_EI_current = partial(multiple_area_customized_op_E, conn_prob=0.1, shape=(1600, 400), area_num=num_area)\n",
    "    self.f_IE_current = partial(multiple_area_customized_op_I, conn_prob=0.1, shape=(400, 1600), area_num=num_area)\n",
    "    self.f_II_current = partial(multiple_area_customized_op_I, conn_prob=0.1, shape=(400, 400), area_num=num_area)\n",
    "\n",
    "    # synapses from I\n",
    "    # self.intra_I2E_conn = bm.random.random((num_area, 400, 1600)) < 0.1\n",
    "    # self.intra_I2I_conn = bm.random.random((num_area, 400, 400)) < 0.1\n",
    "    self.intra_I2E_weight = -wEI\n",
    "    self.intra_I2I_weight = -wII\n",
    "\n",
    "    # synapses from E\n",
    "    # self.E2E_conns = [bm.random.random((num_area, 1600, 1600)) < 0.1 for _ in range(num_area)]\n",
    "    # self.E2I_conns = [bm.random.random((num_area, 1600, 400)) < 0.1 for _ in range(num_area)]\n",
    "    self.E2E_weights = (1 + alpha * hier) * muEE * conn.T  # inter-area connections\n",
    "    bm.fill_diagonal(self.E2E_weights, (1 + alpha * hier) * wEE)  # intra-area connections\n",
    "    self.E2I_weights = (1 + alpha * hier) * muIE * conn.T  # inter-area connections\n",
    "    bm.fill_diagonal(self.E2I_weights, (1 + alpha * hier) * wIE)  # intra-area connections\n",
    "\n",
    "    self.E_seeds = bm.random.randint(0, 100000, (num_area, num_area * 2))\n",
    "    self.I_seeds = bm.random.randint(0, 100000, (num_area * 2))\n",
    "\n",
    "  def update(self, v1_input):\n",
    "    self.E.input[0] += v1_input\n",
    "    self.E.input += self.extE\n",
    "    self.I.input += self.extI\n",
    "    E_not_ref = bm.logical_not(self.E.refractory)\n",
    "    I_not_ref = bm.logical_not(self.I.refractory)\n",
    "\n",
    "    # synapses from E\n",
    "    for i in range(self.num_area):\n",
    "      delayed_E_spikes = self.Edelay(self.E_delay_steps[i], i).astype(float)[i]\n",
    "      current = self.f_EE_current(delayed_E_spikes, self.E2E_weights[i], self.E_seeds[i, :self.num_area])\n",
    "      self.E.V += current * E_not_ref  # E2E\n",
    "      current = self.f_EI_current(delayed_E_spikes, self.E2I_weights[i], self.E_seeds[i, :self.num_area])\n",
    "      self.I.V += current * I_not_ref  # E2I\n",
    "\n",
    "    # synapses from I\n",
    "    delayed_I_spikes = self.Idelay(self.intra_delay_step).astype(float)\n",
    "    current = self.f_IE_current(delayed_I_spikes, self.intra_I2E_weight, self.I_seeds[:self.num_area])\n",
    "    self.E.V += current * E_not_ref  # I2E\n",
    "    current = self.f_II_current(delayed_I_spikes, self.intra_I2I_weight, self.I_seeds[:self.num_area])\n",
    "    self.I.V += current * I_not_ref  # I2I\n",
    "\n",
    "    # updates\n",
    "    self.Edelay.update(self.E.spike)\n",
    "    self.Idelay.update(self.I.spike)\n",
    "    self.E.update()\n",
    "    self.I.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hierarchy values\n",
    "hierVals = loadmat('Joglekar_2018_data/hierValspython.mat')\n",
    "hierValsnew = hierVals['hierVals'].flatten()\n",
    "hier = bm.asarray(hierValsnew / max(hierValsnew))  # hierarchy normalized.\n",
    "\n",
    "# fraction of labeled neurons\n",
    "flnMatp = loadmat('Joglekar_2018_data/efelenMatpython.mat')\n",
    "conn = bm.asarray(flnMatp['flnMatpython'].squeeze())  # fln values..Cij is strength from j to i\n",
    "\n",
    "# Distance\n",
    "speed = 3.5  # axonal conduction velocity\n",
    "distMatp = loadmat('Joglekar_2018_data/subgraphWiring29.mat')\n",
    "distMat = distMatp['wiring'].squeeze()  # distances between areas values..\n",
    "delayMat = bm.asarray(distMat / speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict 9500 steps: :  11%|█▏        | 1086/9500 [00:12<01:16, 110.47it/s]"
     ]
    }
   ],
   "source": [
    "pars = dict(extE=14.2, extI=14.7, wII=.075, wEE=.01, wIE=.075, wEI=.0375, muEE=.0375, muIE=0.0475)\n",
    "inps = dict(value=15, duration=150)\n",
    "\n",
    "inputs, length = bp.inputs.section_input(values=[0, inps['value'], 0.],\n",
    "                                         durations=[300., inps['duration'], 500],\n",
    "                                         return_length=True)\n",
    "\n",
    "net = MultiAreaNet(hier, conn, delayMat, **pars)\n",
    "runner = bp.DSRunner(net, monitors={'E.spike': lambda : net.E.spike.flatten()})\n",
    "runner.run(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the raster plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_plot(xValues, yValues, duration):\n",
    "  ticks = np.round(np.arange(0, 29) + 0.5, 2)\n",
    "  areas = ['V1', 'V2', 'V4', 'DP', 'MT', '8m', '5', '8l', 'TEO', '2', 'F1',\n",
    "           'STPc', '7A', '46d', '10', '9/46v', '9/46d', 'F5', 'TEpd', 'PBr',\n",
    "           '7m', '7B', 'F2', 'STPi', 'PROm', 'F7', '8B', 'STPr', '24c']\n",
    "  N = len(ticks)\n",
    "  plt.figure(figsize=(8, 6))\n",
    "  plt.plot(xValues, yValues / (4 * 400), '.', markersize=1)\n",
    "  plt.plot([0, duration], np.arange(N + 1).repeat(2).reshape(-1, 2).T, 'k-')\n",
    "  plt.ylabel('Area')\n",
    "  plt.yticks(np.arange(N))\n",
    "  plt.xlabel('Time [ms]')\n",
    "  plt.ylim(0, N)\n",
    "  plt.yticks(ticks, areas)\n",
    "  plt.xlim(0, duration)\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "times, indices = np.where(runner.mon['E.spike'])\n",
    "times = runner.mon.ts[times]\n",
    "raster_plot(times, indices, length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
